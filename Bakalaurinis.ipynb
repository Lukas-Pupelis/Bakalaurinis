{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFltRgQKgLAO"
   },
   "source": [
    "### Necessary Libraries and Frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wgHtNEBcf0n4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: optuna in ./.local/lib/python3.8/site-packages (4.3.0)\n",
      "Requirement already satisfied: colorlog in ./.local/lib/python3.8/site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: PyYAML in ./.local/lib/python3.8/site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from optuna) (1.23.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.8/site-packages (from optuna) (1.8.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/site-packages (from optuna) (21.3)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.8/site-packages (from optuna) (1.4.40)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (5.9.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (4.12.0)\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.8/site-packages (from alembic>=1.5.0->optuna) (1.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.0->optuna) (3.0.9)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/site-packages (from sqlalchemy>=1.4.2->optuna) (1.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/site-packages (from importlib-metadata->alembic>=1.5.0->optuna) (3.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.8/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.9.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.23.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./.local/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: segmentation-models-pytorch in ./.local/lib/python3.8/site-packages (0.3.3)\n",
      "Requirement already satisfied: timm in ./.local/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: pretrainedmodels==0.7.4 in ./.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.7.4)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in ./.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.19.1+cu118)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.8/site-packages (from segmentation-models-pytorch) (9.2.0)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (4.67.1)\n",
      "Requirement already satisfied: efficientnet-pytorch==0.7.1 in ./.local/lib/python3.8/site-packages (from segmentation-models-pytorch) (0.7.1)\n",
      "Requirement already satisfied: huggingface-hub in ./.local/lib/python3.8/site-packages (from timm) (0.30.2)\n",
      "Requirement already satisfied: torch>=1.7 in ./.local/lib/python3.8/site-packages (from timm) (2.4.1+cu118)\n",
      "Requirement already satisfied: pyyaml in ./.local/lib/python3.8/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: safetensors in ./.local/lib/python3.8/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: munch in ./.local/lib/python3.8/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.8.89)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (10.3.0.86)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (10.9.0.58)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.20.5 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.8.86)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.7.5.86)\n",
      "Requirement already satisfied: triton==3.0.0 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (3.0.0)\n",
      "Requirement already satisfied: fsspec in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (11.11.3.6)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (3.1)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.8/site-packages (from torch>=1.7->timm) (1.13.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/site-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.local/lib/python3.8/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install scikit-learn\n",
    "!pip install segmentation-models-pytorch timm\n",
    "import os\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "WDYNniSQel-E"
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5\n",
    "IMAGE_SIZE = (384, 512)\n",
    "MEAN = [0.7059, 0.7097, 0.7028]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "THRESHOLD = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-Lt2Z0ymdo2",
    "tags": []
   },
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UBfwi6K0md_d"
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = 'Mikroplastikai/images'\n",
    "MASK_DIR = 'Mikroplastikai/masks'\n",
    "MODEL_PATH = 'microplastic_segmentation_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFTbRWYZgXWd"
   },
   "source": [
    "### Microplastics Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nHKpZAdFgfTc"
   },
   "outputs": [],
   "source": [
    "class MicroplasticsDataset(Dataset):\n",
    "    def __init__(self, image_paths, mask_paths, image_transforms=None, mask_transforms=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.image_transforms = image_transforms\n",
    "        self.mask_transforms = mask_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx])\n",
    "\n",
    "        if self.image_transforms:\n",
    "            image = self.image_transforms(image)\n",
    "\n",
    "        if self.mask_transforms:\n",
    "            mask = self.mask_transforms(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8miGw7RgoYG"
   },
   "source": [
    "### Train and test datasets and data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "VHwdjQfRflaE"
   },
   "outputs": [],
   "source": [
    "def get_data_loaders_and_datasets(train_images, test_images, train_masks, test_masks, batch_size):\n",
    "    # Data transformations\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=MEAN, std=STD)\n",
    "    ])\n",
    "\n",
    "    mask_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # datasets\n",
    "    train_dataset = MicroplasticsDataset(train_images, train_masks, image_transforms=image_transform, mask_transforms=mask_transform)\n",
    "    test_dataset = MicroplasticsDataset(test_images, test_masks, image_transforms=image_transform, mask_transforms=mask_transform)\n",
    "\n",
    "    # loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, test_loader, train_dataset, test_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gK6JDDZTriRU"
   },
   "source": [
    "### Optuna objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DVy9mQk3rgCd"
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    batch_size = trial.suggest_categorical('batch_size', [4, 6, 8, 12, 16])\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'RMSprop', 'SGD'])\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader, test_loader, _, _ = get_data_loaders_and_datasets(train_images, test_images, train_masks, test_masks, batch_size)\n",
    "\n",
    "    # Model\n",
    "    model = smp.Unet(encoder_name='resnet101', encoder_weights='imagenet', in_channels=3, classes=1).to(device)\n",
    "\n",
    "    # Optimizer\n",
    "    if optimizer_name == 'Adam':\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    elif optimizer_name == 'RMSprop':\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "    criterion = smp.losses.DiceLoss(\n",
    "    mode='binary',\n",
    "    from_logits=True\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        for images, masks in train_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in test_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-mgxk8rrqqD"
   },
   "source": [
    "### Hyperparameter fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VjTOWBuiTNIK",
    "outputId": "4a475bb1-d9bc-4f47-d629-c98d8f166c99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.8/site-packages (6.0.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in ./.local/lib/python3.8/site-packages (from plotly) (1.39.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from plotly) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/site-packages (from packaging->plotly) (3.0.9)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-15 14:23:50,488] A new study created in memory with name: no-name-8fd36d7d-76a8-4544-9a77-8086689e3c41\n",
      "[I 2025-05-15 14:40:12,805] Trial 0 finished with value: 0.991955123164437 and parameters: {'batch_size': 8, 'learning_rate': 0.00016005752156053759, 'optimizer': 'SGD'}. Best is trial 0 with value: 0.991955123164437.\n",
      "[I 2025-05-15 14:58:36,779] Trial 1 finished with value: 0.2717207372188568 and parameters: {'batch_size': 6, 'learning_rate': 0.004345398546665549, 'optimizer': 'Adam'}. Best is trial 1 with value: 0.2717207372188568.\n",
      "[W 2025-05-15 15:02:57,683] Trial 2 failed with parameters: {'batch_size': 6, 'learning_rate': 0.009475305219368756, 'optimizer': 'Adam'} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/slurm-lupu8256-173106/ipykernel_90271/693595577.py\", line 31, in objective\n",
      "    outputs = model(images)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py\", line 30, in forward\n",
      "    decoder_output = self.decoder(*features)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/segmentation_models_pytorch/decoders/unet/decoder.py\", line 119, in forward\n",
      "    x = decoder_block(x, skip)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/segmentation_models_pytorch/decoders/unet/decoder.py\", line 41, in forward\n",
      "    x = self.conv2(x)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 219, in forward\n",
      "    input = module(input)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py\", line 176, in forward\n",
      "    return F.batch_norm(\n",
      "  File \"/scratch/lustre/home/lupu8256/.local/lib/python3.8/site-packages/torch/nn/functional.py\", line 2512, in batch_norm\n",
      "    return torch.batch_norm(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-15 15:02:57,694] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Create a study object and perform optimization\u001b[39;00m\n\u001b[1;32m     17\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest hyperparameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, study\u001b[38;5;241m.\u001b[39mbest_trial\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Plot the optimization history\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     29\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 31\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, masks)\n\u001b[1;32m     33\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/segmentation_models_pytorch/base/model.py:30\u001b[0m, in \u001b[0;36mSegmentationModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input_shape(x)\n\u001b[1;32m     29\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[0;32m---> 30\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msegmentation_head(decoder_output)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassification_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/segmentation_models_pytorch/decoders/unet/decoder.py:119\u001b[0m, in \u001b[0;36mUnetDecoder.forward\u001b[0;34m(self, *features)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, decoder_block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks):\n\u001b[1;32m    118\u001b[0m     skip \u001b[38;5;241m=\u001b[39m skips[i] \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(skips) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/segmentation_models_pytorch/decoders/unet/decoder.py:41\u001b[0m, in \u001b[0;36mDecoderBlock.forward\u001b[0;34m(self, x, skip)\u001b[0m\n\u001b[1;32m     39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention1(x)\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m---> 41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention2(x)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    171\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# CHANGED: Pair images and masks by basename for consistency\n",
    "!pip install plotly\n",
    "\n",
    "img_files = sorted(f for f in os.listdir(IMAGE_DIR) if os.path.isfile(os.path.join(IMAGE_DIR, f)))\n",
    "mask_files = sorted(f for f in os.listdir(MASK_DIR) if os.path.isfile(os.path.join(MASK_DIR, f)))\n",
    "img_map = {os.path.splitext(f)[0]: f for f in img_files}\n",
    "mask_map = {os.path.splitext(f)[0]: f for f in mask_files}\n",
    "common = sorted(set(img_map) & set(mask_map))\n",
    "images = [os.path.join(IMAGE_DIR, img_map[k]) for k in common]\n",
    "masks = [os.path.join(MASK_DIR, mask_map[k]) for k in common]\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create a study object and perform optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "print(\"Best hyperparameters:\", study.best_trial.params)\n",
    "\n",
    "# Plot the optimization history\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "# Plot individual hyperparameters' effects on the outcomes\n",
    "fig = optuna.visualization.plot_slice(study)\n",
    "fig.show()\n",
    "\n",
    "# Plot the contour of hyperparameters vs. objective value\n",
    "fig = optuna.visualization.plot_contour(study, params=['batch_size', 'learning_rate', 'optimizer'])\n",
    "fig.show()\n",
    "\n",
    "# Parallel coordinate plot of the hyperparameters\n",
    "fig = optuna.visualization.plot_parallel_coordinate(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "330iyk2hgvwU"
   },
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IWAFsgaLgwkj",
    "outputId": "93fc3a36-b371-4082-f101-d6e59fe737eb"
   },
   "outputs": [],
   "source": [
    "# Train the model with the best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "model = smp.Unet(encoder_name='resnet101', encoder_weights='imagenet', in_channels=3, classes=1).to(device)\n",
    "\n",
    "if best_params['optimizer'] == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'RMSprop':\n",
    "    optimizer = optim.RMSprop(model.parameters(), lr=best_params['learning_rate'])\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_params['learning_rate'], momentum=0.9)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "train_loader, test_loader, train_dataset, test_dataset = get_data_loaders_and_datasets(\n",
    "    train_images, test_images, train_masks, test_masks, best_params['batch_size'])\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "epochs = range(0, len(epoch_accuracy))\n",
    "\n",
    "plot_metrics(epochs, epoch_accuracy, epoch_precision, epoch_recall, epoch_f1, epoch_iou, epoch_losses)\n",
    "\n",
    "print(f'Epoch accuracies: {epoch_accuracy}')\n",
    "print(f'Epoch precisions: {epoch_precision}')\n",
    "print(f'Epoch recalls: {epoch_recall}')\n",
    "print(f'Epoch F1 Scores: {epoch_f1}')\n",
    "print(f'Epoch IoUs: {epoch_iou}')\n",
    "print(f'Epoch losses: {epoch_losses}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ETQJDKlCEgTT",
    "outputId": "4dd6c794-c66d-4ad5-f384-e9773a6543a9"
   },
   "outputs": [],
   "source": [
    "print(accuracy_list)\n",
    "print(precision_list)\n",
    "print(recall_list)\n",
    "print(f1_list)\n",
    "print(iou_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9t5cINPXvpW"
   },
   "source": [
    "### Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_50_oqT1Xux8",
    "outputId": "c39c6f55-d35b-43ca-8773-378b1e7d4b4d"
   },
   "outputs": [],
   "source": [
    "# Initialize lists to store metrics\n",
    "accuracy_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "iou_list = []\n",
    "\n",
    "# Evaluate the model and visualize the results\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    image_counter = 0\n",
    "\n",
    "    for i, (images, masks) in enumerate(test_loader):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        for j in range(images.size(0)):\n",
    "            image_counter += 1\n",
    "\n",
    "            # Apply sigmoid to get probabilities and then threshold to get binary output\n",
    "            predicted_probs = torch.sigmoid(outputs[j])\n",
    "            predicted_mask = (predicted_probs > THRESHOLD).float()\n",
    "\n",
    "            # Convert the tensors to binary format for metric calculation\n",
    "            mask_np = tensor_to_numpy_binary(masks[j])\n",
    "            predicted_mask_np = tensor_to_numpy_binary(predicted_mask)\n",
    "\n",
    "            # Flatten the arrays for metric calculations\n",
    "            mask_np_flat = mask_np.flatten()\n",
    "            predicted_mask_np_flat = predicted_mask_np.flatten()\n",
    "\n",
    "            # Calculate metrics for each image and append to the lists\n",
    "            accuracy_list.append(accuracy_score(mask_np_flat, predicted_mask_np_flat))\n",
    "            precision_list.append(precision_score(mask_np_flat, predicted_mask_np_flat, zero_division=0))\n",
    "            recall_list.append(recall_score(mask_np_flat, predicted_mask_np_flat, zero_division=0))\n",
    "            f1_list.append(f1_score(mask_np_flat, predicted_mask_np_flat, zero_division=0))\n",
    "\n",
    "            iou_score = calculate_iou(predicted_mask_np, mask_np)\n",
    "            iou_list.append(iou_score)\n",
    "\n",
    "            # Visualization - Display the first set of original, normalized, mask, and predicted mask images\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Original Image (without normalization)\n",
    "            original_image_path = test_dataset.image_paths[i * test_loader.batch_size + j]\n",
    "            original_image = Image.open(original_image_path)\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(original_image)\n",
    "            plt.title(f'Orginali Nuotrauka {image_counter}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Ground Truth Mask\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(masks[j].cpu().squeeze(), cmap='gray')\n",
    "            plt.title(f'Tikrasis Užmaskavimas {image_counter}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            # Predicted Mask\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(predicted_mask.cpu().squeeze(), cmap='gray')\n",
    "            plt.title(f'Užmaskavimo Prognozė {image_counter}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "# Calculate and print average metrics\n",
    "avg_accuracy = np.mean(accuracy_list)\n",
    "avg_precision = np.mean(precision_list)\n",
    "avg_recall = np.mean(recall_list)\n",
    "avg_f1 = np.mean(f1_list)\n",
    "avg_iou = np.mean(iou_list)\n",
    "\n",
    "print(f'Average Accuracy: {avg_accuracy:.4f}')\n",
    "print(f'Average Precision: {avg_precision:.4f}')\n",
    "print(f'Average Recall: {avg_recall:.4f}')\n",
    "print(f'Average F1 Score: {avg_f1:.4f}')\n",
    "print(f'Average IoU: {avg_iou:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-QOviOKg0Zm"
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'microplastic_segmentation_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZnX36xkrFoN"
   },
   "source": [
    "### Additional plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "7_rQln7g4C7t",
    "outputId": "05bab035-667a-4082-9709-f6889b74883f"
   },
   "outputs": [],
   "source": [
    "plot_metrics(epochs, epoch_accuracy, None, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "Qf0dorPiDI-b",
    "outputId": "9e110fc2-8832-48bd-c60f-2102a0aacc76"
   },
   "outputs": [],
   "source": [
    "plot_metrics(epochs, None, None, None, None, None, epoch_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Idb7APdIDPn3"
   },
   "outputs": [],
   "source": [
    "# All metrics with 10 skipped epoch results\n",
    "epochs_skipped = epochs[10:]\n",
    "epoch_accuracy_skipped = epoch_accuracy[10:]\n",
    "epoch_precision_skipped = epoch_precision[10:]\n",
    "epoch_recall_skipped = epoch_recall[10:]\n",
    "epoch_f1_skipped = epoch_f1[10:]\n",
    "epoch_iou_skipped = epoch_iou[10:]\n",
    "epoch_losses_skipped = epoch_losses[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "ougBVNNcEQT2",
    "outputId": "7034d9c7-ee59-4dbc-e329-26459f6a2a88"
   },
   "outputs": [],
   "source": [
    "plot_metrics_skipped(epochs_skipped, epoch_accuracy_skipped, epoch_precision_skipped, epoch_recall_skipped, epoch_f1_skipped, epoch_iou_skipped, epoch_losses_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "s1U5f5HQEZkI",
    "outputId": "e8e7e995-ed2e-4965-8d8c-547f7069fd9b"
   },
   "outputs": [],
   "source": [
    "plot_metrics_skipped(epochs_skipped, epoch_accuracy_skipped, None, None, None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 568
    },
    "id": "Icdw5OucESNW",
    "outputId": "149dac67-84b6-49a0-f5e5-293a1783430e"
   },
   "outputs": [],
   "source": [
    "plot_metrics_skipped(epochs_skipped, None, None, None, None, None, epoch_losses_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "04CbBJhwHE5a",
    "outputId": "8cefdbbf-2c80-4c26-c213-dd50d46e73b7"
   },
   "outputs": [],
   "source": [
    "plot_metrics_skipped(epochs_skipped, None, epoch_precision_skipped, epoch_recall_skipped, epoch_f1_skipped, epoch_iou_skipped, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A3PZDkZopt3Z"
   },
   "source": [
    "### Calcualte mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tb9i3aJ-IC5k",
    "outputId": "54227416-221e-4b53-8fa9-b61b89aff671"
   },
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_paths = [os.path.join(image_dir, img) for img in os.listdir(image_dir) if img.endswith(('png', 'jpg', 'jpeg'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(\n",
    "    image_dir=IMAGE_DIR,\n",
    "    transform=image_transform\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=10, shuffle=False, num_workers=1)\n",
    "\n",
    "# Function to calculate mean and std\n",
    "def calculate_mean_std(loader):\n",
    "    mean = 0.\n",
    "    std = 0.\n",
    "    total_images_count = 0\n",
    "\n",
    "    for images in loader:\n",
    "        batch_samples = images.size(0)\n",
    "        images = images.view(batch_samples, images.size(1), -1)\n",
    "        mean += images.mean(2).sum(0)\n",
    "        std += images.std(2).sum(0)\n",
    "        total_images_count += batch_samples\n",
    "\n",
    "    mean /= total_images_count\n",
    "    std /= total_images_count\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "mean, std = calculate_mean_std(loader)\n",
    "print(f'Mean: {mean}')\n",
    "print(f'Std: {std}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IM_tMxayuApa"
   },
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKeAv9TkuAQl"
   },
   "outputs": [],
   "source": [
    "def tensor_to_numpy_binary(tensor):\n",
    "    return tensor.cpu().detach().numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tw5-U3F3uXM3"
   },
   "outputs": [],
   "source": [
    "def calculate_iou(predicted, target):\n",
    "    intersection = np.logical_and(target, predicted)\n",
    "    union = np.logical_or(target, predicted)\n",
    "    if np.sum(union) == 0:\n",
    "        iou_score = 0.0\n",
    "    else:\n",
    "        iou_score = np.sum(intersection) / np.sum(union)\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8mCis-CEu_K1"
   },
   "outputs": [],
   "source": [
    "def plot_metrics(epochs, accuracy, precision, recall, f1, iou, losses):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Metrics\n",
    "    if (accuracy != None):\n",
    "      plt.plot(epochs, accuracy, label='Tikslumas')\n",
    "    if (precision != None):\n",
    "      plt.plot(epochs, precision, label='Preciziškumas')\n",
    "    if (recall != None):\n",
    "      plt.plot(epochs, recall, label='Atkūrimo statistika')\n",
    "    if (f1 != None):\n",
    "      plt.plot(epochs, f1, label='F1')\n",
    "    if (iou != None):\n",
    "      plt.plot(epochs, iou, label='IoU')\n",
    "    if (losses != None):\n",
    "      plt.plot(epochs, losses, label='Nuostolis')\n",
    "\n",
    "    plt.xlabel('Epizodas')\n",
    "    plt.ylabel('Metrika')\n",
    "    plt.title('Metrikų rezultatai epochose')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(np.arange(0, last_epoch + 1, 5))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lhzGDFexEGH4"
   },
   "outputs": [],
   "source": [
    "def plot_metrics_skipped(epochs, accuracy, precision, recall, f1, iou, losses):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    if accuracy is not None:\n",
    "        plt.plot(epochs, accuracy, label='Tikslumas')\n",
    "    if precision is not None:\n",
    "        plt.plot(epochs, precision, label='Preciziškumas')\n",
    "    if recall is not None:\n",
    "        plt.plot(epochs, recall, label='Atkūrimo statistika')\n",
    "    if f1 is not None:\n",
    "        plt.plot(epochs, f1, label='F1')\n",
    "    if iou is not None:\n",
    "        plt.plot(epochs, iou, label='IoU')\n",
    "    if losses is not None:\n",
    "        plt.plot(epochs, losses, label='Nuostolis')\n",
    "\n",
    "    plt.xlabel('Epizodas')\n",
    "    plt.ylabel('Metrika')\n",
    "    plt.title('Metrikų rezultatai epochose')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.xticks(np.arange(10, last_epoch + 1, 5))\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
